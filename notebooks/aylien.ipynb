{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import aylien_news_api\n",
    "from aylien_news_api.rest import ApiException\n",
    "from pprint import pprint\n",
    "import copy\n",
    "import dotenv\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Configure API key authorization: app_id\n",
    "app_id = dotenv.get_key('../.env', 'AYLIEN_APP_ID')\n",
    "app_key = dotenv.get_key('../.env', 'AYLIEN_APP_KEY')\n",
    "endpoint = dotenv.get_key('../.env', 'AYLIEN_ENDPOINT')\n",
    "\n",
    "configuration = aylien_news_api.Configuration()\n",
    "configuration.api_key['X-AYLIEN-NewsAPI-Application-ID'] = app_id\n",
    "configuration.api_key['X-AYLIEN-NewsAPI-Application-Key'] = app_key\n",
    "configuration.host = endpoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "client = aylien_news_api.ApiClient(configuration)\n",
    "api_instance = aylien_news_api.DefaultApi(client)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Fetch stories using AYLIEN News API\n",
    "def fetch_stories_to_file(opts, append_to_file, limit=None):\n",
    "    response = None\n",
    "    fetched_stories = []\n",
    "    stories = None\n",
    "    RETRY_COUNT = 5\n",
    "    MAX_PER_PAGE = 100\n",
    "    retry = 0\n",
    "\n",
    "    def _end_of_file():\n",
    "        if append_to_file:\n",
    "            with open(append_to_file, 'rb+') as f:\n",
    "                # Remove trailing comma if present\n",
    "                f.seek(-2, os.SEEK_END)\n",
    "                if str(f.read(1), 'utf-8') == ',':\n",
    "                    print(\"Removing trailing comma.\")\n",
    "                    f.seek(-1, os.SEEK_CUR)\n",
    "                    f.truncate()\n",
    "                    f.write(bytes('\\n]\\n', 'utf-8'))\n",
    "\n",
    "    if append_to_file and os.path.exists(append_to_file):\n",
    "        with open(append_to_file, 'r+') as f:\n",
    "            if (start := f.read(1)) == '[':\n",
    "                print(\"append_to non-empty.\")\n",
    "            elif start:\n",
    "                print(\"append_to non-empty, but doesn't start with '['. Stopping.\")\n",
    "                return fetched_stories\n",
    "            else:\n",
    "                print(\"append_to empty. Will overwrite\")\n",
    "                f.write('[\\n')\n",
    "\n",
    "        with open(append_to_file, 'rb+') as f:\n",
    "            f.seek(-2, os.SEEK_END)\n",
    "            final = str(f.read(1), 'utf-8')\n",
    "            f.seek(-2, os.SEEK_CUR)\n",
    "            if final == ']':\n",
    "                print(\"append_to ends with ']'. Removing.\")\n",
    "                f.truncate()\n",
    "                f.write(bytes(',\\n', 'utf-8'))\n",
    "            elif final == ',' or final == '[':\n",
    "                print(\"append_to ends with \" + final + \". Will append to end.\")\n",
    "            else:\n",
    "                print(\"append_to doesn't end with ',' or ']'. Check that it's valid JSON and that the file ends with newline. Stopping.\")\n",
    "                return fetched_stories\n",
    "\n",
    "    while stories is None or len(stories) == (opts.get('per_page') or MAX_PER_PAGE):\n",
    "        if limit and len(fetched_stories) >= limit:\n",
    "            print('Reached limit of %d stories' % limit)\n",
    "            print('Next page cursor: %s' % response.next_page_cursor or 'None')\n",
    "            _end_of_file()\n",
    "            return fetched_stories\n",
    "        try:\n",
    "            response = api_instance.list_stories(**opts)\n",
    "        except ApiException as e:\n",
    "            if e.status == 429:\n",
    "                if int(e.headers['x-ratelimit-volume-remaining']) == 0:\n",
    "                    reset = e.headers('x-ratelimit-volume-reset')\n",
    "                    print('Monthly rate limit exceeded. Wait until reset at %s' % reset)\n",
    "                    print('Next page cursor: %s' % response.next_page_cursor or 'None')\n",
    "                    _end_of_file()\n",
    "                    return fetched_stories\n",
    "                if int(e.headers['x-ratelimit-remaining']) == 0:\n",
    "                    print('1-Minute rate limit exceeded. Waiting 60 seconds...')\n",
    "                    time.sleep(60)\n",
    "                    continue\n",
    "            else:\n",
    "                print(\"Exception when calling DefaultApi->list_stories (see below)\")\n",
    "                print(\"Retry %d/%d\" % (retry, RETRY_COUNT))\n",
    "                print(\"Status: %d\" % e.status)\n",
    "                print(\"Reason: %s\" % e.reason)\n",
    "                if retry < RETRY_COUNT:\n",
    "                    print(\"Retrying in 10 seconds...\")\n",
    "                    retry += 1\n",
    "                    time.sleep(10)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"Giving up. Check end of file '%s' for partial results.\" % append_to_file)\n",
    "                    print('Next page cursor: %s' % response.next_page_cursor or 'None')\n",
    "                    _end_of_file()\n",
    "                    return fetched_stories\n",
    "\n",
    "        if append_to_file:\n",
    "            with open(append_to_file, 'a') as f:\n",
    "                for story in response.stories:\n",
    "                    sentiment_dict = {'body_polarity': story.sentiment.body.polarity if story.sentiment.body else None,\n",
    "                                      'body_score': story.sentiment.body.score if story.sentiment.body else None,\n",
    "                                      'title_polarity': story.sentiment.title.polarity if story.sentiment.title else None,\n",
    "                                      'title_score': story.sentiment.title.score if story.sentiment.title else None}\n",
    "\n",
    "                    source_dict = {\n",
    "                        'description': story.source.description if story.source else None,\n",
    "                        'discriminator': story.source.discriminator if story.source else None,\n",
    "                        'domain': story.source.domain if story.source else None,\n",
    "                        'home_page_url': story.source.home_page_url if story.source else None,\n",
    "                        'id': story.source.id if story.source else None,\n",
    "                        'links_in_count': story.source.links_in_count if story.source else None\n",
    "                    }\n",
    "\n",
    "                    story_dict = {'document_id': story.id, 'body': story.body, 'date': story.published_at.isoformat(),\n",
    "                                  'sentiment': sentiment_dict, 'source': source_dict}\n",
    "                    fetched_stories.append(story_dict)\n",
    "                    json.dump(story_dict, f, indent=4)\n",
    "                    f.write(',\\n')\n",
    "\n",
    "        stories = response.stories\n",
    "        opts['cursor'] = response.next_page_cursor\n",
    "\n",
    "        print(f'Fetched {len(stories)} stories. Total: {len(fetched_stories)} so far.')\n",
    "\n",
    "    _end_of_file()\n",
    "    return fetched_stories\n",
    "\n",
    "# Alternate: Fetch stories using pure HTTP requests\n",
    "def fetch_news(api_id, api_key, opts):\n",
    "    base_url = 'https://api.aylien.com/news/stories'\n",
    "    headers = {\n",
    "        'X-AYLIEN-NewsAPI-Application-ID': api_id,\n",
    "        'X-AYLIEN-NewsAPI-Application-Key': api_key\n",
    "    }\n",
    "    params = {\n",
    "        'published_at.start': opts['published_at_start'],\n",
    "        'published_at.end': opts['published_at_end'],\n",
    "        # 'source_locations.country': ','.join(opts['source_locations_country']),\n",
    "        # 'language': ','.join(opts['language']),\n",
    "        'sort_by': opts['sort_by'],\n",
    "        # 'sort_direction': opts['sort_direction'],\n",
    "        'per_page': opts['per_page'],\n",
    "    }\n",
    "    if 'aql' in opts:\n",
    "        params['aql'] = opts['aql']\n",
    "    elif 'text' in opts:\n",
    "        params['text'] = opts['text']\n",
    "\n",
    "    response = requests.get(base_url, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error when calling AYLIEN News API: {response.status_code}, {response.text}\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# generate AYLIEN Query Language (AQL, based on Lucene) query from keywords\n",
    "keywords_file = '../models/story_keywords.txt'\n",
    "with open(keywords_file, 'r') as f:\n",
    "    keywords = f.read().splitlines()\n",
    "\n",
    "climate_keywords_aql = 'text:(' + ' OR '.join([f'\"{keyword}\"' for keyword in keywords]) + ')'\n",
    "\n",
    "# generate AQL query from bill info\n",
    "bill_data_file = '../data/bill_data.json'\n",
    "with open(bill_data_file, 'r') as f:\n",
    "    bill_data = json.load(f)\n",
    "\n",
    "bill_aql_tuples = [(f'\"{bill[\"short_title\"]}\"', f'\"{bill[\"bill_number\"]}\"') for bill in bill_data.values()]\n",
    "half = len(bill_aql_tuples) // 2\n",
    "\n",
    "bill_aql_1 = 'text:(' + ' OR '.join([st + ' OR ' + bn for st, bn in bill_aql_tuples[:half]]) + ')'\n",
    "bill_aql_2 = 'text:(' + ' OR '.join([st + ' OR ' + bn for st, bn in bill_aql_tuples[half:]]) + ')'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# set options\n",
    "opts_1 = {\n",
    "    'aql': bill_aql_1,\n",
    "    'published_at_start': 'NOW-27MONTH',\n",
    "    'published_at_end': 'NOW-1DAY',\n",
    "    'source_locations_country': ['US'],\n",
    "    'language': ['en'],\n",
    "    'sort_by': 'relevance',\n",
    "    # 'sort_direction': 'asc',\n",
    "    'per_page': 100,\n",
    "}\n",
    "\n",
    "opts_2 = copy.deepcopy(opts_1)\n",
    "opts_2['aql'] = bill_aql_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "append_to non-empty.\n",
      "append_to ends with ']'. Removing.\n",
      "Fetched 100 stories. Total: 100 so far.\n",
      "Fetched 100 stories. Total: 200 so far.\n",
      "Reached limit of 200 stories\n",
      "Next page cursor: MjEwLjIwOTA5LDM4MDE3NDQ1NTc=\n",
      "Removing trailing comma.\n"
     ]
    }
   ],
   "source": [
    "fetched = fetch_stories_to_file(opts_1, append_to_file='../data/fetched_stories.json', limit=3000)\n",
    "# TODO: fetch for opts_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
